\chapter{Background}\label{chap:background}

This chapter presents fundamental concepts for understanding and development of the 
work. Section~\ref{sec:type-systems} reviews concepts related to type systems and 
Section~\ref{sec:operational-semantics} reviews concepts related to operational 
semantics. Section~\ref{sec:pegs} formally introduces PEGs and their 
operational semantics. Related work is discussed in Section~\ref{sec:related-work}.
Section~\ref{sec:background-conclusion} concludes the chapter.

\section{Type systems}\label{sec:type-systems}

\section{Operational semantics}\label{sec:operational-semantics}

\section{An Overview of PEGs}\label{sec:pegs}

Intuitively, PEGs are a formalism for describing top-down parsers.
Formally, a PEG is a 4-tuple \((V,\Sigma,R,e_S)\), where \(V\) is a 
finite set of variables, \(\Sigma\) is the alphabet, \(R\) is the finite 
set of rules, and \(e_S\) is the start expression. Each rule \(r \in R\) is a 
pair \((A,e)\), usually written \(A \leftarrow e\), where \(A \in V\) and \(e\) 
is a parsing expression. We let the meta-variable \(a\) denote an 
arbitrary alphabet symbol, \(A\) a variable and \(e\) a parsing expression. 
Following common practice, all meta-variables can appear primed or 
sub-scripted. The following context-free grammar defines
the syntax of a parsing expression:
\[
   \begin{array}{lcl}
      e & \to & \epsilon \, \mid \, a \, \mid \, A\, \mid \,e_1\:e_2\,
                  \mid\,e_1\,/\,e_2\, \mid \,e^\star\, \mid \,!\,e \\
   \end{array}
\]
The execution of parsing expressions is defined by an inductively defined
judgment that relates pairs formed by a parsing expression and an input string
to pairs formed by the consumed prefix and the remaining string.
Notation \((e,s) \Rightarrow_G (s_p,s_r)\) denote that parsing expression \(e\)
consumes the prefix \(s_p\) from the input string \(s\) leaving the suffix \(s_r\).
The notation \((e,s) \Rightarrow_G \bot\) denote the fact that \(s\) cannot be 
parsed by \(e\). We let meta-variable \(r\) denote an arbitrary parsing result, i.e.,
either \(r\) is a pair \((s_p,s_r)\) or \(\bot\). We say that an expression \(e\)
fails if its execution over an input produces \(\bot\); otherwise, it succeeds.
Figure~\ref{fig:pegsemantics} defines the PEG semantics.
\begin{figure*}[!ht]
   \[
      \begin{array}{cccc}
         \infer[_{\{Eps\}}]{(\epsilon,s)\Rightarrow_G (\epsilon,s)}{} &
         \infer[_{\{ChrS\}}]{(a,as_r) \Rightarrow_G (a,s_r)}{}  &
         \infer[_{\{ChrF\}}]{(a,bs_r) \Rightarrow_G \bot}{a \neq b} &
         \infer[_{\{Var\}}]{(A,s) \Rightarrow_G r}
                           {A \leftarrow e \in R & (e,s) \Rightarrow_G r} \\ \\
         \multicolumn{2}{c}{
            \infer[_{\{Cat_{S1}\}}]{(e_1\,e_2,s_{p_1}s_{p_2}s_r) \Rightarrow_G (s_{p_1}s_{p_2}, s_r)}
                                 {(e_1,s_{p_1}s_{p_2}s_r) \Rightarrow_G (s_{p_1},s_{p_2}s_r) &
                                 (e_2,s_{p_2}s_r)\Rightarrow_G (s_{p_2},s_r)}
         } &
         \multicolumn{2}{c}{
            \infer[_{\{Cat_{F2}\}}]{(e_1\,e_2,s_ps_r) \Rightarrow_G \bot}
                                 { (e_1,s_ps_r) \Rightarrow_G (s_p,s_r) &
                                    (e_2,s_r) \Rightarrow_G \bot}} \\ \\
         \infer[_{\{Cat_{F1}\}}]{(e_1\,e_2,s)\Rightarrow_G \bot}{(e_1,s) \Rightarrow_G \bot} &
         \infer[_{\{Alt_{S1}\}}]{(e_1\,/\,e_2,s_p\,s_r) \Rightarrow_G (s_p,s_r)}
                                {(e_1,s_p\,s_r)\Rightarrow_G (s_p,s_r)} &
         \multicolumn{2}{c}{
            \infer[_{\{Alt_{S2}\}}]{(e_1\,/\,e_2,s_p\,s_r) \Rightarrow_G r}
                                  {(e_1,s_p\,s_r)\Rightarrow_G \bot &
                                   (e_2,s_p\,s_r)\Rightarrow_G r}
         } \\ \\
         \multicolumn{2}{c}{
            \infer[_{\{Star_{rec}\}}]{(e^\star,s_{p_1}s_{p_2}s_r) \Rightarrow_G (s_{p_1}s_{p_2},s_r)}
                                 {(e,s_{p_1}s_{p_2}s_r) \Rightarrow_G (s_{p_1},s_{p_2}s_r) &
                                  (e^\star, s_{p_2}s_r) \Rightarrow_G (s_{p_2},s_r)}
         } &
         \multicolumn{2}{c}{
            \infer[_{\{Star_{end}\}}]{(e^\star,s) \Rightarrow_G (\epsilon,s)}
                                    {(e,s) \Rightarrow_G \bot}} \\ \\
         \multicolumn{2}{c}{
            \infer[_{\{Not_F\}}]{(!\,e,s_p\,s_r) \Rightarrow_G \bot}
                               {(e,s_p\,s_r) \Rightarrow_G (s_p,s_r)}
         } &
         \infer[_{\{Not_S\}}]{(!\,e,s) \Rightarrow_G (\epsilon,s)}
         {(e,s) \Rightarrow_G \bot}
           &
         \infer[_{\{ChrNil\}}]{(a,\epsilon) \Rightarrow_G \bot}{}
      \end{array}
   \]
   \centering
   \caption{Parsing expressions operational semantics.}
   \label{fig:pegsemantics}
\end{figure*}
We comment on some rules of the semantics. Rule \(_{Eps}\) specifies that
expression \(\epsilon\) will not fail on any input \(s\) by leaving it unchanged.
Rule \(_{ChrS}\) specifies that an expression \(a\) consumes the first character when
the input string starts with an `a' and rule \(_{ChrF}\) shows that it fails when
the input starts with a different symbol. Rule \(_{Var}\) parses the input using
the expression associated with the variable in the grammar \(G\). When parsing a
sequence expression, \(e_1\:e_2\), the result is formed by \(e_1\) and \(e_2\) parsed
prefixes and the remaining input is given by \(e_2\). Rules \(_{Cat_{F1}}\) and
\(_{Cat_{F2}}\) say that if \(e_1\) or \(e_2\) fail, then the whole expression fails.
The rules for choice impose that we only try
expression \(e_2\) in \(e_1 / e_2\) when \(e_1\) fails. Parsing a star
expression \(e^\star\) consists in repeatedly execute \(e\) on the input string.
When \(e\) fails, \(e^\star\) succeeds without consuming any symbol of the input
string. Finally, the rules for the not predicate expression, \(!\,e\), specify
that whenever the expression \(e\) succeeds on input \(s\), \(!\,e\) fails; and when \(e\)
fails on \(s\) we have that \(!\,e\) succeeds without consuming any input.

\begin{example}
   As an example, consider the PEG (Figure~\ref{fig:peg-math-formulas}) which 
   recognizes mathematical formulas that apply the basic four operations to 
   non-negative integers:
   
   \begin{figure*}[ht]
      \[
         \begin{array}{lcl}
            \text{E}   & \leftarrow & \text{T ('+' T)*} \\
            \text{T}  & \leftarrow & \text{F ('*' F)*} \\
            \text{F} & \leftarrow & \text{[0-9]+ / '(' Expr ')'} \\
         \end{array}
      \] 
      \centering
      \caption{PEG for mathematical formulas.}   
      \label{fig:peg-math-formulas}
   \end{figure*}

   \textbf{-- Montar árvore de derivação da semântica para 1+2 --}
   \textbf{-- Eu troco [0-9]+ pra n na PEG e deixo como n na árvore? 
              Ou troco pra [0-9]+ na árvore e continuo a derivação? --}
   \begin{sidewaysfigure*}
      \footnotesize
      \[
         \infer[]{
            \langle E, 1+2 \rangle \Rightarrow_G \langle 1+2, \epsilon \rangle
         }{
            \infer[]{
               \langle T ('+' T)^\star, 1+2 \rangle \Rightarrow_G \langle 1+2, \epsilon \rangle
            }{
               \infer[]{
                  \langle T, 1+2 \rangle \Rightarrow_G \langle 1, +2 \rangle
               }{
                  \infer[]{
                     \langle F ('*' F)^\star, 1+2 \rangle \Rightarrow_G \langle 1, +2 \rangle
                  }{
                     \infer[]{
                        \langle F, 1+2 \rangle 
                     }{
                        \infer[]{
                           \langle n / '(' E ')', 1+2 \rangle \Rightarrow_G \langle 1, +2 \rangle
                        }{
                           \infer[]{
                              \langle n, 1+2 \rangle \Rightarrow_G \langle 1, +2 \rangle
                           }{}
                        }
                     }
                     &
                     \infer[]{
                        \langle ('*' F)^\star, +2 \rangle \Rightarrow_G \langle \epsilon, +2 \rangle
                     }{
                        \infer[]{
                           \langle '*' F, +2 \rangle \Rightarrow_G \langle \bot, +2 \rangle
                        }{}
                     }
                  }
               }
               &
               \infer[]{
                  \langle ('+' T)^\star, +2 \rangle \Rightarrow_G \langle +2, \epsilon \rangle
               }{
                  \infer[]{
                     \langle '+' T, +2\rangle \Rightarrow_G \langle +2, \epsilon \rangle
                  }{
                     \infer[]{
                        \langle '+', +2 \rangle \Rightarrow_G \langle +, 2 \rangle
                     }{}
                     &
                     \infer[]{
                        \langle T, 2 \rangle \Rightarrow_G \langle 2, \epsilon \rangle
                     }{
                        \infer[]{
                           \langle F ('*' F)^\star, 2 \rangle \Rightarrow_G \langle 2, \epsilon \rangle
                        }{
                           \infer[]{
                              \langle F, 2 \rangle \Rightarrow_G \langle 2, \epsilon \rangle
                           }{
                              \infer[]{
                                 \langle n / '(' E ')', 2 \rangle \Rightarrow_G \langle 2, \epsilon \rangle
                              }{
                                 \infer[]{
                                    \langle n, 2 \rangle \Rightarrow_G \langle 2, \epsilon \rangle
                                 }{}
                              }
                           }
                           &
                           \infer[]{
                              \langle ('*' F)^\star, \epsilon \rangle \Rightarrow_G \langle \epsilon, \epsilon \rangle
                           }{
                              \infer[]{
                                 \langle '*' F, \epsilon \rangle \Rightarrow_G \langle \bot, \epsilon \rangle
                              }{}
                           }
                        }
                     }
                  }
                  &
                  \infer[]{
                     \langle ('+' T)^\star, \epsilon \rangle \Rightarrow_G \langle \epsilon, \epsilon \rangle
                  }{
                     \infer[]{
                        \langle '+' T, \epsilon \rangle \Rightarrow_G \langle \bot, \epsilon \rangle
                     }{}
                  }
               }
            }
         }
      \]
      \centering
      \caption{Semantic derivation for expression `1+2*3'}
      \label{fig:peg-math-derivation}
   \end{sidewaysfigure*}
   
   Consider the string \texttt{1+2}. The initial rule \texttt{E}, first tries to 
   parse a \texttt{T} that will, in turn, first try to consume a \texttt{F}, which 
   recognizes the number \texttt{'1'}. Since the \texttt{T} rule does not consume 
   a \texttt{'*'}, it returns back to \texttt{E}. It then finds the \texttt{'+'} 
   operator and tries to parse another \texttt{T}, which will consume the 2 as a 
   \texttt{F} and goes back to \texttt{E}, that does not find another \texttt{'+'} 
   operator and finalizes the parsing process. The derivation tree for the string 
   \texttt{1+2} can be seen on Figure~\ref{fig:peg-math-derivation}.
   
   % \begin{figure*}
   %    \begin{tikzpicture}[
   %       level distance=0.8cm,
   %       sibling distance=2cm,
   %       every node/.style={
   %          draw,
   %          shape=ellipse,
   %          minimum height=7mm,
   %          minimum width=7mm,
   %          inner sep=2pt,
   %          anchor=north
   %       }
   %    ]
   
   %       \node {Expr}
   %       child {node {E}
   %          child {node {T}
   %             child {node {F}
   %                child {node {1}}
   %             }
   %          }
   %          child {node {+}}
   %          child {node {T}
   %             child {node {F}
   %                child {node {2}}
   %             }
   %             child {node {*} }
   %             child {node {F}
   %                child {node {3}}
   %             }
   %          }
   %       };
   %    \end{tikzpicture}
   %    \centering
   %    \caption{Generated abstract syntax tree for the expression 1+2*3}
   %    \label{fig:generated-ast}
   % \end{figure*}
\end{example}

\section{Related work}\label{sec:related-work}

Atkinson and Griswold~\cite{atkinson2006-effective-pattern-matching} presents 
the matching tool TAWK, which extends extend the pattern syntax of AWK to 
support matching of abstract syntax trees. In TAWK, pattern syntax is 
language-independent, based on abstract tree patterns, and each pattern can 
have associated actions, which are written in C for generality, familirity 
and performance. An example of extracting a call graph from a given code is 
presented throughout the paper, providing examples in different pattern matching 
tools, including TAWK, and a scorecard for each, detailing four characteristics:
matching power, programming power, speed and robustness.

Kopell et al.~\cite{kopell2018-language-parametric-transformation} presents an
approach for building source-to-source transformation that can run on multiple
programming languages, based on a representation called incremental parametric
syntax (IPS).
In IPS, languages are represented using a mixture of language-specific and 
generic parts. Transformations deal only with the generic fragments, but 
the implementer starts with a pre-existing normal syntax definition, and 
only does enough up-front work to redefine a small fraction of a language 
in terms of these generic fragments.
The IPS was implemented in a Haskell framework called \textit{Cubix}, 
and currently supports C, Java, JavaScript, Lua, and Python\footnote{
See \url{https://github.com/cubix-framework/cubix}}.
They also demonstrate a whole-program refactoring for threading variables
through chains of function calls and three smaller source-to-source 
transformations, being a hoisting transformation, a test-coverage 
transformation and a the three-address code transformation.

Premtoon et al.~\cite{premtoon2020-code-search-equational-reasoning} presents 
\textit{Yogo}, a tool that uses an approach to semantic code search 
based on equational reasoning, that considers not only the dataflow graph of 
a function, but also the dataflow graphs of all equivalents functions reachable 
via a set of rewrite rules~\cite{premtoon2020-code-search-equational-reasoning}. 
The tool is capable of recognizing differents variations of the same operation 
and also when code is an instance of a higher-level concept.
\textit{Yogo} is built on the \textit{Cubix} infraestructure and can find 
equivalent code in multiple languages from a single query.

Silva et al.~\cite{silva2021-refdiff} proposes \textit{RefDiff 2.0}, a 
multi-language refactoring detection tool. Their approach introduces a 
refactoring detection algorithm that relies on the Code Structure Tree 
(CST), a representation of the source code that abstract away the 
specificities of particular programming languages. 
The tool has results that are on par with state-of-the-art refactoring 
detection approaches specialized in the Java language. It also has support 
for two other popular programming languages: JavaScript and C. This
demonstrates that the tool can be a viable alternative for multi-language
refactoring research and in practical applications of refactoring detection.

van Tonder and Le Goues~\cite{vanTonder2019-syntax-transformation-ppc} proposes
that the problem of automatically transforming programs can be decomposed by 
having a common grammar and open extension points. The common grammar expresses 
the central context-free language (CFL) properties shared by many contemporary 
languages, while the open extensions points allow customizing syntax and hooks 
in smaller parsers to handle language-specific syntax, such as comments. 
The decomposition is made using a Parser Parser combinator (PPC), a mechanism 
that generates parsers for matching syntactic fragments in source code by parsing 
declarative user-supplied templates. 
This allows to detach from translating input programs to any particular 
abstract syntax tree representation, and lifts syntax rewriting to a 
modularly-defined parsing problem. 
They also evaluate \textit{Comby}, an implementation of the approach process 
using PPC, on a large scale multi-language rewriting across 12 languages, and 
validated effectiveness of the approach by producing correct and desirable 
lightweight transformations on popular real-world projects.

Matute et al.~\cite{matute2024-sequence-tree-matching} proposes a search
architecture that relies only on tokenizing a query, introducing a new 
language and matching algorithm to support tree-aware wildcards by building
on tree automata. They also present \textit{stsearch}, a syntactic search
tool leveraging their approach, which supports syntactic search even for
previously unparsable queries.

Ierusalimschy~\cite{ierusalimschy2009-lpeg} proposes the use of PEGs as a basis
for text pattern-mathing and presents LPEG, a text pattern-matching tool based on 
PEGs for the Lua scripting language, and a Parsing Machine that allows a small 
and efficient implementation of PEGs for pattern matching. 
This allow LPEG to have both the expressive power of PEGs with the ease of use 
of regular expressions.
LPEG also seems specially suited for languages that are too complex for 
traditional pattern-matching tools but do not need a complex yacc-lex 
implementation, like domain-specific languages such as SQL and regular
expressions, and even XML.

Of the approaches found in the literature, only LPEG uses the concept of PEGs, 
trying to combine their expressive capacity with the ease of use of regular 
expressions, but it focuses on text matching. The approach presented in this 
work uses PEGs to generate a parse tree and perform the matching (and rewriting) 
of these trees.

\section{Conclusion}\label{sec:background-conclusion}

This chapter presents the theoretical framework for this work: initially, concepts 
about type systems and operational semantics were reviewed. Next, the concept 
of PEGs and their operational semantics were presented. Finally, works related 
to source code analysis and pattern matching were presented.

\cleardoublepage